# Emotion Encoding in Human-Drone Interaction 

*by Jessica R. Cauchard, Kevin Y. Zhai, Marco Spadafora, and James A. Landay, in HRI '16* - [10.1109/HRI.2016.7451761](https://doi.org/10.1109/HRI.2016.7451761)

### 1) What are the core research questions investigated through empirical studies?

How can three defined emotional states be encoded for human recognition using drone flight paths?

### 2) What empirical methods have been used to study the research questions?

1. WoZ study with 20 participants investigating how a drone's movements and reactions to specific commands are interpreted as an emotional state.

### 3) What kind of drone and/or other apparatus was used?

AR Parrot 2.0 Drone and custom web-based interface

### 4) What results have been obtained from the studies?

- While the "adventurer/hero" (happy, brave) model was well-identified, the "exhausted" (dopey, sad, sleepy) and "anti-social" (grumpy, shy) models were not accurately identified by participants.
- When allowing for a "second guess," identification rates for all three models were high.
- Participants often correctly identified the task or action that the drone was undertaking, but identification of its emotional state (on the first guess) was more challenging.
- Participants often compared the drone's behavior to that of a pet and based their expectations on animal behavior.

### 5) How do the results inform design?

- Flight parameters such as flight path, reaction time, altitute, orientation, and speed; as well as reactivity/compliance, are effective in establishing intuitively comprehensible drone behaviors.
- Human interpretations of drone behavior are often based on expectations formed by animal behavior.
